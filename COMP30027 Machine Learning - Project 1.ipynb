{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2018 Semester 1\n",
    "-----\n",
    "## Project 1: What is labelled data worth to Naive Bayes?\n",
    "-----\n",
    "###### Student Name(s): Emmanuel Macario\n",
    "###### Python version: 3.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you may use for your Project 1 submission. (You are not required to use it; in particular, there is no need to use iPython if you do not like it.)\n",
    "\n",
    "Marking will be applied on the seven functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5\n",
       "0  vhigh  vhigh  2  2  small   low\n",
       "1  vhigh  vhigh  2  2  small   med\n",
       "2  vhigh  vhigh  2  2  small  high\n",
       "3  vhigh  vhigh  2  2    med   low\n",
       "4  vhigh  vhigh  2  2    med   med"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filename constants used for easy file access\n",
    "CSV1 = 'breast-cancer-dos.csv'\n",
    "CSV2 = 'car-dos.csv'\n",
    "CSV3 = 'hypothyroid-dos.csv'\n",
    "CSV4 = 'mushroom-dos.csv'\n",
    "\n",
    "\n",
    "def preprocess(filename):\n",
    "    \"\"\"\n",
    "    Opens a data file in csv, and transforms it into\n",
    "    a usable format.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read csv data into a dataframe. Assign\n",
    "    # an integer value to each attribute in\n",
    "    # the data.\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Partition the data into instances and\n",
    "    # instance class labels.\n",
    "    instance_list = df.iloc[:,:-1]\n",
    "    class_list = df.iloc[:,-1]\n",
    "    data_set = instance_list, class_list\n",
    "    \n",
    "    # Note: the instance list is a dataframe, whereas the class\n",
    "    # list is a series object\n",
    "    \n",
    "    return data_set\n",
    "\n",
    "\n",
    "# Test preprocess function\n",
    "instance_list, class_list = preprocess(CSV2)\n",
    "instance_list.head(5)\n",
    "\n",
    "# instance_list.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_supervised(instance_list, class_list):\n",
    "    \"\"\"\n",
    "    Builds a supervised Naive Bays model,\n",
    "    given a preprocessed set of training\n",
    "    data, by calculating counts from the\n",
    "    training data.\n",
    "    \n",
    "    Inputs: a training set of data, consisting\n",
    "    of a list of instances, and a list of class \n",
    "    labels for those instances.\n",
    "    \n",
    "    Outputs: 2-tuple containing a class frequency \n",
    "    dictionary and also the supervised model.\n",
    "    \"\"\"\n",
    "        \n",
    "    # The supervised Naive Bays model\n",
    "    supervised_model = {}\n",
    "    \n",
    "    # For every instance in the training\n",
    "    # data, update the model\n",
    "    for i in range(len(instance_list)):\n",
    "        \n",
    "        # Get the instance\n",
    "        instance = instance_list.iloc[i,:]\n",
    "        \n",
    "        # Get the associated class label\n",
    "        class_label = class_list[i]\n",
    "        \n",
    "        \n",
    "        # If the class label is not already in\n",
    "        # the model, create a nested set of\n",
    "        # dictionaries for the class.\n",
    "        if class_label not in supervised_model:\n",
    "            \n",
    "            # New dictionary for every new class\n",
    "            supervised_model[class_label] = {}\n",
    "            \n",
    "            # For each attribute, initialise\n",
    "            # a new default dictionary.\n",
    "            for attr in instance_list.columns:\n",
    "                supervised_model[class_label][attr] = defaultdict(int)\n",
    "                \n",
    "        \n",
    "        # For every attribute in the instance,\n",
    "        # get its corresponding value and update\n",
    "        # the model.\n",
    "        for attr in instance_list.columns:\n",
    "            attr_value = instance[attr]\n",
    "            supervised_model[class_label][attr][attr_value] += 1\n",
    "    \n",
    "    \n",
    "    return supervised_model\n",
    "\n",
    "\n",
    "\n",
    "# Test function\n",
    "supervised_model = train_supervised(instance_list, class_list)\n",
    "\n",
    "# supervised_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_class_freqs(supervised_model):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing frequency counts\n",
    "    of all the class labels in the training data.\n",
    "    \"\"\"\n",
    "    \n",
    "    class_freqs = defaultdict(int)\n",
    "    \n",
    "    for class_label in supervised_model:\n",
    "        class_freqs[class_label] = sum(supervised_model[class_label][0].values())\n",
    "        \n",
    "    return class_freqs\n",
    "\n",
    "\n",
    "\n",
    "def predict_supervised(supervised_model, instance_list):\n",
    "    \"\"\"\n",
    "    Predicts the class labels for a set of test\n",
    "    instances, based on a supervised Naive Bayes\n",
    "    model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The list of predictions for each instance\n",
    "    prediction_list = []\n",
    "    \n",
    "    # Get the class frequencies to avoid redundant calculations\n",
    "    class_freqs = get_class_freqs(supervised_model)\n",
    "    \n",
    "    # Calculate the total number of instances\n",
    "    total_instances = sum(class_freqs.values())\n",
    "    \n",
    "    \n",
    "    # For each instance in the test set, predict \n",
    "    # its class based on the supervised model.\n",
    "    for instance in instance_list.values:\n",
    "        \n",
    "        max_prob = 0.0\n",
    "        predicted_class = \"\"\n",
    "        \n",
    "        # We obtain the probability of an instance\n",
    "        # being a certain class, for each possible class.\n",
    "        for class_label in class_freqs:\n",
    "            \n",
    "            # Firstly, get the prior probability of a class\n",
    "            prob = class_freqs[class_label]/total_instances\n",
    "            \n",
    "            \n",
    "            # Now, multiply the prior probability of the class\n",
    "            # by the posterior probability of each of the instance's \n",
    "            # attribute values, given the class.\n",
    "            for attr in supervised_model[class_label]:\n",
    "                prob *= (supervised_model[class_label][attr][instance[attr]]/class_freqs[class_label])\n",
    "                \n",
    "            \n",
    "            # If the probability is the highest seen\n",
    "            # thus far, set the predicted class to the\n",
    "            # class label.\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                predicted_class = class_label\n",
    "            \n",
    "        \n",
    "        # Add the class label with the highest\n",
    "        # corresponding probability to the list\n",
    "        # of predictions.\n",
    "        prediction_list.append(predicted_class)\n",
    "        \n",
    "        \n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "# Test the function\n",
    "prediction_list = predict_supervised(supervised_model, instance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8738425925925926"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def evaluate_supervised(prediction_list, class_list):\n",
    "    \"\"\"\n",
    "    Evaluates a set of predictions, in a supervised\n",
    "    context. Uses accuracy as the primary method of\n",
    "    evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validation checking\n",
    "    assert(len(prediction_list) == len(class_list))\n",
    "    \n",
    "    # Calculate and return the accuracy of the model\n",
    "    return (prediction_list == class_list).value_counts().loc[True]/len(prediction_list)\n",
    "\n",
    "\n",
    "# Test the function\n",
    "evaluate_supervised(prediction_list, class_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_unsupervised(instance_list, class_labels):\n",
    "    \"\"\"\n",
    "    Builds a weak unsupervised Naive Bayes model,\n",
    "    from a given set of unlabelled training data,\n",
    "    and a unique set of possible class labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The list containing random class\n",
    "    # distributions for each instance.\n",
    "    random_class_distributions = []\n",
    "    \n",
    "    \n",
    "    # For each training instance, create\n",
    "    # a non-uniform class distribution for\n",
    "    # that instance.\n",
    "    for instance in instance_list.values:\n",
    "        \n",
    "        random_class_distributions.append(\n",
    "            np.random.dirichlet(np.ones(len(class_labels)),size=1)[0])\n",
    "        \n",
    "    \n",
    "    # Make a new dataframe consisting of random class distributions\n",
    "    # for each instance.\n",
    "    class_distributions = pd.DataFrame(random_class_distributions, \n",
    "                                       columns=class_labels)   \n",
    "        \n",
    "    \n",
    "    # Dictionary contains the (random) frequencies\n",
    "    # of each class in the training set\n",
    "    class_freqs = defaultdict(int) \n",
    "    \n",
    "    \n",
    "    # Count the frequencies\n",
    "    for class_label in class_labels:\n",
    "        class_freqs[class_label] = class_distributions[class_label].sum()\n",
    "    \n",
    "    \n",
    "    # Initialise the unsupervised Naive Bays model, which\n",
    "    # is just a dictionary of dictionaries of dictionaries\n",
    "    unsupervised_model = {c : {a : defaultdict(float) for a in instance_list.columns} for c in class_labels}\n",
    "    \n",
    "    \n",
    "    # Concatenate the dataframes\n",
    "    # class_distributions = pd.concat([instance_list, class_distributions], axis=1)\n",
    "    \n",
    "\n",
    "    # For every instance in the training\n",
    "    # data, update the unsupervised model\n",
    "    for i in range(len(instance_list)):\n",
    "        \n",
    "        for attr in instance_list.columns:\n",
    "            \n",
    "            for class_label in class_labels:\n",
    "                \n",
    "                unsupervised_model[class_label][attr][instance_list[attr][i]] += class_distributions[class_label][i]\n",
    "                \n",
    "    \n",
    "    return class_distributions, class_freqs, unsupervised_model\n",
    "\n",
    "\n",
    "\n",
    "# Test the function\n",
    "class_labels = class_list.unique()\n",
    "cd, cf, um = train_unsupervised(instance_list, class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unacc</th>\n",
       "      <th>acc</th>\n",
       "      <th>vgood</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.240607</td>\n",
       "      <td>0.275175</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.244318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.233886</td>\n",
       "      <td>0.281088</td>\n",
       "      <td>0.218848</td>\n",
       "      <td>0.266177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276751</td>\n",
       "      <td>0.260007</td>\n",
       "      <td>0.237114</td>\n",
       "      <td>0.226128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.247589</td>\n",
       "      <td>0.297136</td>\n",
       "      <td>0.214954</td>\n",
       "      <td>0.240321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.240167</td>\n",
       "      <td>0.302883</td>\n",
       "      <td>0.195679</td>\n",
       "      <td>0.261272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.284661</td>\n",
       "      <td>0.280638</td>\n",
       "      <td>0.212367</td>\n",
       "      <td>0.222334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.239144</td>\n",
       "      <td>0.276237</td>\n",
       "      <td>0.239652</td>\n",
       "      <td>0.244968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.232430</td>\n",
       "      <td>0.282132</td>\n",
       "      <td>0.218590</td>\n",
       "      <td>0.266847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.275157</td>\n",
       "      <td>0.261095</td>\n",
       "      <td>0.236945</td>\n",
       "      <td>0.226803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.240639</td>\n",
       "      <td>0.270011</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.249350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.233840</td>\n",
       "      <td>0.275722</td>\n",
       "      <td>0.218867</td>\n",
       "      <td>0.271570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.276812</td>\n",
       "      <td>0.255150</td>\n",
       "      <td>0.237233</td>\n",
       "      <td>0.230806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.247747</td>\n",
       "      <td>0.291707</td>\n",
       "      <td>0.215152</td>\n",
       "      <td>0.245394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.240244</td>\n",
       "      <td>0.297255</td>\n",
       "      <td>0.195797</td>\n",
       "      <td>0.266704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.284859</td>\n",
       "      <td>0.275526</td>\n",
       "      <td>0.212575</td>\n",
       "      <td>0.227041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.239177</td>\n",
       "      <td>0.271055</td>\n",
       "      <td>0.239753</td>\n",
       "      <td>0.250015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.232386</td>\n",
       "      <td>0.276748</td>\n",
       "      <td>0.218610</td>\n",
       "      <td>0.272255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.275219</td>\n",
       "      <td>0.256219</td>\n",
       "      <td>0.237065</td>\n",
       "      <td>0.231496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.236482</td>\n",
       "      <td>0.276156</td>\n",
       "      <td>0.235882</td>\n",
       "      <td>0.251480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.229617</td>\n",
       "      <td>0.281772</td>\n",
       "      <td>0.214940</td>\n",
       "      <td>0.273671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.272322</td>\n",
       "      <td>0.261237</td>\n",
       "      <td>0.233413</td>\n",
       "      <td>0.233027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.243281</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>0.211299</td>\n",
       "      <td>0.247302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.235732</td>\n",
       "      <td>0.303555</td>\n",
       "      <td>0.192143</td>\n",
       "      <td>0.268570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.280038</td>\n",
       "      <td>0.281898</td>\n",
       "      <td>0.209002</td>\n",
       "      <td>0.229062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.235031</td>\n",
       "      <td>0.277207</td>\n",
       "      <td>0.235626</td>\n",
       "      <td>0.252136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.228175</td>\n",
       "      <td>0.282804</td>\n",
       "      <td>0.214675</td>\n",
       "      <td>0.274345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.270739</td>\n",
       "      <td>0.262316</td>\n",
       "      <td>0.233235</td>\n",
       "      <td>0.233710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.224561</td>\n",
       "      <td>0.266783</td>\n",
       "      <td>0.264788</td>\n",
       "      <td>0.243868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.218716</td>\n",
       "      <td>0.273050</td>\n",
       "      <td>0.242026</td>\n",
       "      <td>0.266208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.258865</td>\n",
       "      <td>0.252634</td>\n",
       "      <td>0.262291</td>\n",
       "      <td>0.226210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>0.217152</td>\n",
       "      <td>0.239681</td>\n",
       "      <td>0.265719</td>\n",
       "      <td>0.277448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>0.210961</td>\n",
       "      <td>0.244687</td>\n",
       "      <td>0.242258</td>\n",
       "      <td>0.302093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>0.250859</td>\n",
       "      <td>0.227455</td>\n",
       "      <td>0.263776</td>\n",
       "      <td>0.257909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>0.247861</td>\n",
       "      <td>0.240471</td>\n",
       "      <td>0.272606</td>\n",
       "      <td>0.239061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>0.241975</td>\n",
       "      <td>0.246697</td>\n",
       "      <td>0.249755</td>\n",
       "      <td>0.261572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>0.284238</td>\n",
       "      <td>0.226533</td>\n",
       "      <td>0.268630</td>\n",
       "      <td>0.220598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>0.256561</td>\n",
       "      <td>0.261197</td>\n",
       "      <td>0.245703</td>\n",
       "      <td>0.236540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>0.249882</td>\n",
       "      <td>0.267331</td>\n",
       "      <td>0.224580</td>\n",
       "      <td>0.258207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>0.294020</td>\n",
       "      <td>0.245895</td>\n",
       "      <td>0.241959</td>\n",
       "      <td>0.218127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>0.246409</td>\n",
       "      <td>0.241454</td>\n",
       "      <td>0.272386</td>\n",
       "      <td>0.239752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>0.240523</td>\n",
       "      <td>0.247669</td>\n",
       "      <td>0.249518</td>\n",
       "      <td>0.262290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>0.282664</td>\n",
       "      <td>0.227532</td>\n",
       "      <td>0.268499</td>\n",
       "      <td>0.221306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>0.247756</td>\n",
       "      <td>0.235827</td>\n",
       "      <td>0.272568</td>\n",
       "      <td>0.243850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>0.241791</td>\n",
       "      <td>0.241851</td>\n",
       "      <td>0.249636</td>\n",
       "      <td>0.266722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>0.284150</td>\n",
       "      <td>0.222184</td>\n",
       "      <td>0.268623</td>\n",
       "      <td>0.225042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>0.256567</td>\n",
       "      <td>0.256268</td>\n",
       "      <td>0.245779</td>\n",
       "      <td>0.241386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>0.249808</td>\n",
       "      <td>0.262202</td>\n",
       "      <td>0.224577</td>\n",
       "      <td>0.263413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>0.294053</td>\n",
       "      <td>0.241276</td>\n",
       "      <td>0.242055</td>\n",
       "      <td>0.222615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>0.246306</td>\n",
       "      <td>0.236791</td>\n",
       "      <td>0.272348</td>\n",
       "      <td>0.244555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>0.240341</td>\n",
       "      <td>0.242805</td>\n",
       "      <td>0.249399</td>\n",
       "      <td>0.267454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>0.282577</td>\n",
       "      <td>0.223164</td>\n",
       "      <td>0.268493</td>\n",
       "      <td>0.225765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>0.243843</td>\n",
       "      <td>0.241558</td>\n",
       "      <td>0.268295</td>\n",
       "      <td>0.246304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>0.237775</td>\n",
       "      <td>0.247523</td>\n",
       "      <td>0.245519</td>\n",
       "      <td>0.269182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>0.279952</td>\n",
       "      <td>0.227819</td>\n",
       "      <td>0.264686</td>\n",
       "      <td>0.227542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>0.252325</td>\n",
       "      <td>0.262298</td>\n",
       "      <td>0.241744</td>\n",
       "      <td>0.243632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>0.245480</td>\n",
       "      <td>0.268157</td>\n",
       "      <td>0.220713</td>\n",
       "      <td>0.265650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>0.289506</td>\n",
       "      <td>0.247222</td>\n",
       "      <td>0.238341</td>\n",
       "      <td>0.224931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>0.242402</td>\n",
       "      <td>0.242532</td>\n",
       "      <td>0.268064</td>\n",
       "      <td>0.247002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>0.236336</td>\n",
       "      <td>0.248485</td>\n",
       "      <td>0.245272</td>\n",
       "      <td>0.269906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>0.278386</td>\n",
       "      <td>0.228811</td>\n",
       "      <td>0.264543</td>\n",
       "      <td>0.228260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         unacc       acc     vgood      good\n",
       "0     0.240607  0.275175  0.239900  0.244318\n",
       "1     0.233886  0.281088  0.218848  0.266177\n",
       "2     0.276751  0.260007  0.237114  0.226128\n",
       "3     0.247589  0.297136  0.214954  0.240321\n",
       "4     0.240167  0.302883  0.195679  0.261272\n",
       "5     0.284661  0.280638  0.212367  0.222334\n",
       "6     0.239144  0.276237  0.239652  0.244968\n",
       "7     0.232430  0.282132  0.218590  0.266847\n",
       "8     0.275157  0.261095  0.236945  0.226803\n",
       "9     0.240639  0.270011  0.240000  0.249350\n",
       "10    0.233840  0.275722  0.218867  0.271570\n",
       "11    0.276812  0.255150  0.237233  0.230806\n",
       "12    0.247747  0.291707  0.215152  0.245394\n",
       "13    0.240244  0.297255  0.195797  0.266704\n",
       "14    0.284859  0.275526  0.212575  0.227041\n",
       "15    0.239177  0.271055  0.239753  0.250015\n",
       "16    0.232386  0.276748  0.218610  0.272255\n",
       "17    0.275219  0.256219  0.237065  0.231496\n",
       "18    0.236482  0.276156  0.235882  0.251480\n",
       "19    0.229617  0.281772  0.214940  0.273671\n",
       "20    0.272322  0.261237  0.233413  0.233027\n",
       "21    0.243281  0.298118  0.211299  0.247302\n",
       "22    0.235732  0.303555  0.192143  0.268570\n",
       "23    0.280038  0.281898  0.209002  0.229062\n",
       "24    0.235031  0.277207  0.235626  0.252136\n",
       "25    0.228175  0.282804  0.214675  0.274345\n",
       "26    0.270739  0.262316  0.233235  0.233710\n",
       "27    0.224561  0.266783  0.264788  0.243868\n",
       "28    0.218716  0.273050  0.242026  0.266208\n",
       "29    0.258865  0.252634  0.262291  0.226210\n",
       "...        ...       ...       ...       ...\n",
       "1698  0.217152  0.239681  0.265719  0.277448\n",
       "1699  0.210961  0.244687  0.242258  0.302093\n",
       "1700  0.250859  0.227455  0.263776  0.257909\n",
       "1701  0.247861  0.240471  0.272606  0.239061\n",
       "1702  0.241975  0.246697  0.249755  0.261572\n",
       "1703  0.284238  0.226533  0.268630  0.220598\n",
       "1704  0.256561  0.261197  0.245703  0.236540\n",
       "1705  0.249882  0.267331  0.224580  0.258207\n",
       "1706  0.294020  0.245895  0.241959  0.218127\n",
       "1707  0.246409  0.241454  0.272386  0.239752\n",
       "1708  0.240523  0.247669  0.249518  0.262290\n",
       "1709  0.282664  0.227532  0.268499  0.221306\n",
       "1710  0.247756  0.235827  0.272568  0.243850\n",
       "1711  0.241791  0.241851  0.249636  0.266722\n",
       "1712  0.284150  0.222184  0.268623  0.225042\n",
       "1713  0.256567  0.256268  0.245779  0.241386\n",
       "1714  0.249808  0.262202  0.224577  0.263413\n",
       "1715  0.294053  0.241276  0.242055  0.222615\n",
       "1716  0.246306  0.236791  0.272348  0.244555\n",
       "1717  0.240341  0.242805  0.249399  0.267454\n",
       "1718  0.282577  0.223164  0.268493  0.225765\n",
       "1719  0.243843  0.241558  0.268295  0.246304\n",
       "1720  0.237775  0.247523  0.245519  0.269182\n",
       "1721  0.279952  0.227819  0.264686  0.227542\n",
       "1722  0.252325  0.262298  0.241744  0.243632\n",
       "1723  0.245480  0.268157  0.220713  0.265650\n",
       "1724  0.289506  0.247222  0.238341  0.224931\n",
       "1725  0.242402  0.242532  0.268064  0.247002\n",
       "1726  0.236336  0.248485  0.245272  0.269906\n",
       "1727  0.278386  0.228811  0.264543  0.228260\n",
       "\n",
       "[1728 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_unsupervised(class_distributions, unsupervised_model, instance_list, iterations=10):\n",
    "    \"\"\"\n",
    "    Predicts the class distribution for a set of\n",
    "    instances, based on a trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the class frequencies to avoid recalculation\n",
    "    class_freqs = get_class_freqs(unsupervised_model)\n",
    "    \n",
    "    \n",
    "    # Calculate the total number of instances\n",
    "    total_instances = int(sum(class_freqs.values()) + 0.5)\n",
    "    \n",
    "    \n",
    "    # For each instance in the test set, iteratively\n",
    "    # update the class distribution for the instance\n",
    "    for iteration in range(iterations):\n",
    "    \n",
    "        for i in range(len(instance_list)):\n",
    "\n",
    "            # Get the instance\n",
    "            instance = instance_list.iloc[i,:]\n",
    "\n",
    "\n",
    "            # Find a new class distribution for the instance,\n",
    "            # then normalise that distribution.\n",
    "            for class_label in class_freqs:\n",
    "\n",
    "                # Firstly, get the prior probability of a class\n",
    "                prob = class_freqs[class_label]/total_instances\n",
    "\n",
    "                # Now, multiply the prior probability of the class\n",
    "                # by the posterior probability of each of the instance's \n",
    "                # attribute values, given the class.\n",
    "                for attr in unsupervised_model[class_label]:\n",
    "                    prob *= (unsupervised_model[class_label][attr][instance[attr]]/class_freqs[class_label])\n",
    "\n",
    "\n",
    "                # Update the probability distribution for the instance\n",
    "                class_distributions[class_label][i] = prob\n",
    "\n",
    "\n",
    "        # Now, normalise the class distribution so that the probabilities add to 1\n",
    "        class_distributions = class_distributions.div(class_distributions.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    return class_distributions\n",
    "\n",
    "\n",
    "predict_unsupervised(cd, um, instance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_unsupervised():\n",
    "    \"\"\"\n",
    "    Evaluates a set of predictions, in an\n",
    "    unsupervised manner.\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. Since we’re starting off with random guesses, it might be surprising that the unsupervised NB works at all. Explain what characteristics of the data cause it to work pretty well (say, within 10% Accuracy of the supervised NB) most of the time; also, explain why it utterly fails sometimes.\n",
    "2. When evaluating supervised NB across the four different datasets, you will observe some variation in effectiveness (e.g. Accuracy). Explain what causes this variation. Describe and explain any particularly suprising results.\n",
    "3. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out (hint: check out numpy.shuffle()) or cross–validation evaluation strategy. How does your estimate of Accuracy change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "4. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Do you notice any variation in the predictions made by either the supervised or unsupervised NB classifiers? Explain why, or why not.\n",
    "5. The lecture suggests that deterministically labelling the instances in the initialisation phase of the unsupervised NB classifier “doesn’t work very well”. Confirm this for yourself, and then demonstrate why.\n",
    "6. Rather than evaluating the unsupervised NB classifier by assigning a class deterministically, instead calculate how far away the probabilistic estimate of the true class is from 1 (where we would be certain of the correct class), and take the average over the instances. Does this performance estimate change, as we alter the number of iterations in the method? Explain why.\n",
    "7. Explore what causes the unsupervised NB classifier to converge: what proportion of instances change their prediction from the random assignment, to the first iteration? From the first to the second? What is the latest iteration where you observe a prediction change? Make some conjecture(s) as to what is occurring here.\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question. Groups of 2 students should respond to question (1), and three other questions. Your responses should be about 100-200 words each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
