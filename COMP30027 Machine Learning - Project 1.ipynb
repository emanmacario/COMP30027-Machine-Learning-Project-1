{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2018 Semester 1\n",
    "-----\n",
    "## Project 1: What is labelled data worth to Naive Bayes?\n",
    "-----\n",
    "###### Student Name(s): Emmanuel Macario\n",
    "###### Python version: 3.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you may use for your Project 1 submission. (You are not required to use it; in particular, there is no need to use iPython if you do not like it.)\n",
    "\n",
    "Marking will be applied on the seven functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filename constants used for easy file access\n",
    "CSV1 = 'breast-cancer-dos.csv'\n",
    "CSV2 = 'car-dos.csv'\n",
    "CSV3 = 'hypothyroid-dos.csv'\n",
    "CSV4 = 'mushroom-dos.csv'\n",
    "\n",
    "\n",
    "def preprocess(filename):\n",
    "    \"\"\"\n",
    "    Opens a data file in csv, and transforms it into\n",
    "    a usable format.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read csv data into a dataframe. Assign\n",
    "    # an integer value to each attribute in\n",
    "    # the data.\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Partition the data into instances and\n",
    "    # instance class labels.\n",
    "    #instance_list = df.iloc[:,:-1]\n",
    "    #class_list = df.iloc[:,-1]\n",
    "    #data_set = instance_list, class_list\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Test preprocess function\n",
    "df = preprocess(CSV2)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': {0: defaultdict(int,\n",
       "              {'high': 108, 'low': 89, 'med': 115, 'vhigh': 72}),\n",
       "  1: defaultdict(int, {'high': 105, 'low': 92, 'med': 115, 'vhigh': 72}),\n",
       "  2: defaultdict(int, {'2': 81, '3': 99, '4': 102, '5more': 102}),\n",
       "  3: defaultdict(int, {'4': 198, 'more': 186}),\n",
       "  4: defaultdict(int, {'big': 144, 'med': 135, 'small': 105}),\n",
       "  5: defaultdict(int, {'high': 204, 'med': 180})},\n",
       " 'good': {0: defaultdict(int, {'low': 46, 'med': 23}),\n",
       "  1: defaultdict(int, {'low': 46, 'med': 23}),\n",
       "  2: defaultdict(int, {'2': 15, '3': 18, '4': 18, '5more': 18}),\n",
       "  3: defaultdict(int, {'4': 36, 'more': 33}),\n",
       "  4: defaultdict(int, {'big': 24, 'med': 24, 'small': 21}),\n",
       "  5: defaultdict(int, {'high': 30, 'med': 39})},\n",
       " 'unacc': {0: defaultdict(int,\n",
       "              {'high': 324, 'low': 258, 'med': 268, 'vhigh': 360}),\n",
       "  1: defaultdict(int, {'high': 314, 'low': 268, 'med': 268, 'vhigh': 360}),\n",
       "  2: defaultdict(int, {'2': 326, '3': 300, '4': 292, '5more': 292}),\n",
       "  3: defaultdict(int, {'2': 576, '4': 312, 'more': 322}),\n",
       "  4: defaultdict(int, {'big': 368, 'med': 392, 'small': 450}),\n",
       "  5: defaultdict(int, {'high': 277, 'low': 576, 'med': 357})},\n",
       " 'vgood': {0: defaultdict(int, {'low': 39, 'med': 26}),\n",
       "  1: defaultdict(int, {'high': 13, 'low': 26, 'med': 26}),\n",
       "  2: defaultdict(int, {'2': 10, '3': 15, '4': 20, '5more': 20}),\n",
       "  3: defaultdict(int, {'4': 30, 'more': 35}),\n",
       "  4: defaultdict(int, {'big': 40, 'med': 25}),\n",
       "  5: defaultdict(int, {'high': 65})}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function should build a supervised NB model\n",
    "def train_supervised(df):\n",
    "    \"\"\"\n",
    "    Builds a supervised Naive Bays model,\n",
    "    given a preprocessed set of training\n",
    "    data, by calculating counts from the\n",
    "    training data.\n",
    "    \n",
    "    Inputs: a training set of data, consisting\n",
    "    of a list of instances, and a list of class \n",
    "    labels for those instances.\n",
    "    \n",
    "    Outputs: 2-tuple containing a class frequency \n",
    "    dictionary and also the supervised model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary contains the frequencies\n",
    "    # of each class in the training set\n",
    "    class_freqs = defaultdict(int) \n",
    "    \n",
    "    # The supervised Naive Bays model\n",
    "    supervised_model = {}\n",
    "    \n",
    "    # For every instance in the training\n",
    "    # data, update the model\n",
    "    for instance in df.values:\n",
    "        \n",
    "        # Get the instance's class label\n",
    "        class_label = instance[-1]\n",
    "        \n",
    "        \n",
    "        # Update the class frequency dictionary\n",
    "        class_freqs[class_label] += 1\n",
    "        \n",
    "        \n",
    "        # If the class label is not already in\n",
    "        # the model, create a nested set of\n",
    "        # dictionaries for the class.\n",
    "        if class_label not in supervised_model:\n",
    "            \n",
    "            # New dictionary for every new class\n",
    "            supervised_model[class_label] = {}\n",
    "            \n",
    "            # For each attribute, initialise\n",
    "            # a new default dictionary.\n",
    "            for attr in df.columns[:-1]:\n",
    "                supervised_model[class_label][attr] = defaultdict(int)\n",
    "            \n",
    "            \n",
    "        # For every attribute in the instance,\n",
    "        # get its corresponding value and update\n",
    "        # the model.\n",
    "        for attr in df.columns[:-1]:\n",
    "            attr_value = instance[attr]\n",
    "            supervised_model[class_label][attr][attr_value] += 1\n",
    "    \n",
    "    \n",
    "    return class_freqs, supervised_model\n",
    "\n",
    "\n",
    "\n",
    "# Test function\n",
    "class_freqs, supervised_model = train_supervised(df)\n",
    "\n",
    "\n",
    "supervised_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_supervised(df, class_freqs, supervised_model):\n",
    "    \"\"\"\n",
    "    Predicts the class labels for a set of\n",
    "    instances, based on a supervised Naive Bayes\n",
    "    model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # A list of predictions for each instance\n",
    "    prediction_list = []\n",
    "    \n",
    "    # Calculate the total number of instances\n",
    "    total_instances = sum(class_freqs.values())\n",
    "    \n",
    "    # For each instance, predict the class\n",
    "    # based on our model.\n",
    "    for instance in df.values:\n",
    "        \n",
    "        max_prob = 0\n",
    "        predicted_class = \"\"\n",
    "        \n",
    "        # Test each class label to see what the predicted class\n",
    "        for class_label in class_freqs:\n",
    "            \n",
    "            # The prior probability of a class\n",
    "            prob = class_freqs[class_label]/total_instances\n",
    "            \n",
    "            \n",
    "            # Multiply the prior probability of the predicted class\n",
    "            # by the posterior probability of the instance attribute\n",
    "            # value, given the class.\n",
    "            for attr in supervised_model[class_label]:\n",
    "                prob *= (supervised_model[class_label][attr][instance[attr]]/class_freqs[class_label])\n",
    "                \n",
    "            \n",
    "            # If the probability is the highest seen\n",
    "            # thus far, set the predicted class to the\n",
    "            # class label.\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                predicted_class = class_label\n",
    "            \n",
    "        \n",
    "        # Add the predicted class to our list\n",
    "        prediction_list.append(predicted_class)\n",
    "        \n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "# Test the function\n",
    "prediction_list = predict_supervised(df, class_freqs, supervised_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8738425925925926\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_supervised(prediction_list, class_list):\n",
    "    \"\"\"\n",
    "    Evaluates a set of predictions, in a supervised\n",
    "    context. Uses accuracy as the primary method of\n",
    "    evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validation checking\n",
    "    assert(len(prediction_list) == len(class_list))\n",
    "    \n",
    "    # Calculate and return the accuracy of the model\n",
    "    return (prediction_list == class_list).value_counts().loc[True]/len(prediction_list)\n",
    "\n",
    "\n",
    "# Test the function\n",
    "class_list = df.iloc[:,-1]\n",
    "accuracy = evaluate_supervised(prediction_list, class_list)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': {0: defaultdict(float,\n",
       "              {'high': 110.99402382097131,\n",
       "               'low': 102.5091940086595,\n",
       "               'med': 108.06575047706308,\n",
       "               'vhigh': 104.81144309206324}),\n",
       "  1: defaultdict(float,\n",
       "              {'high': 103.05346500612374,\n",
       "               'low': 100.28445360851963,\n",
       "               'med': 112.0701254575236,\n",
       "               'vhigh': 110.97236732659022}),\n",
       "  2: defaultdict(float,\n",
       "              {'2': 108.84403345375087,\n",
       "               '3': 103.14136597931672,\n",
       "               '4': 109.10402696222378,\n",
       "               '5more': 105.2909850034657}),\n",
       "  3: defaultdict(float,\n",
       "              {'2': 142.92674910860012,\n",
       "               '4': 148.32967893906454,\n",
       "               'more': 135.12398335109245}),\n",
       "  4: defaultdict(float,\n",
       "              {'big': 135.85779060830637,\n",
       "               'med': 139.81450182405047,\n",
       "               'small': 150.7081189664002}),\n",
       "  5: defaultdict(float,\n",
       "              {'high': 145.6547231944667,\n",
       "               'low': 143.8547709199649,\n",
       "               'med': 136.87091728432557})},\n",
       " 'good': {0: defaultdict(float,\n",
       "              {'high': 106.69913551021732,\n",
       "               'low': 109.89037661658543,\n",
       "               'med': 108.5688267627428,\n",
       "               'vhigh': 110.33920535641113}),\n",
       "  1: defaultdict(float,\n",
       "              {'high': 109.9628732092878,\n",
       "               'low': 112.79446362036292,\n",
       "               'med': 104.95592512368496,\n",
       "               'vhigh': 107.78428229262134}),\n",
       "  2: defaultdict(float,\n",
       "              {'2': 107.12428199102092,\n",
       "               '3': 107.03579194832786,\n",
       "               '4': 111.33900984421184,\n",
       "               '5more': 109.99846046239638}),\n",
       "  3: defaultdict(float,\n",
       "              {'2': 146.56306418936157,\n",
       "               '4': 141.1971622470691,\n",
       "               'more': 147.7373178095261}),\n",
       "  4: defaultdict(float,\n",
       "              {'big': 154.04842877843552,\n",
       "               'med': 146.69545651470503,\n",
       "               'small': 134.75365895281618}),\n",
       "  5: defaultdict(float,\n",
       "              {'high': 138.15984933483378,\n",
       "               'low': 154.50238082908044,\n",
       "               'med': 142.83531408204266})},\n",
       " 'unacc': {0: defaultdict(float,\n",
       "              {'high': 112.97988751296681,\n",
       "               'low': 112.458398160327,\n",
       "               'med': 111.57924069896544,\n",
       "               'vhigh': 106.00354927224647}),\n",
       "  1: defaultdict(float,\n",
       "              {'high': 110.51320076887305,\n",
       "               'low': 110.00552298772368,\n",
       "               'med': 112.06838621424936,\n",
       "               'vhigh': 110.43396567365963}),\n",
       "  2: defaultdict(float,\n",
       "              {'2': 112.79678032062215,\n",
       "               '3': 113.86693342654172,\n",
       "               '4': 108.33015614386922,\n",
       "               '5more': 108.02720575347266}),\n",
       "  3: defaultdict(float,\n",
       "              {'2': 146.86802174563758,\n",
       "               '4': 145.11228411173366,\n",
       "               'more': 151.04076978713414}),\n",
       "  4: defaultdict(float,\n",
       "              {'big': 141.94656907476008,\n",
       "               'med': 150.3414233477297,\n",
       "               'small': 150.73308322201555}),\n",
       "  5: defaultdict(float,\n",
       "              {'high': 147.24541812068006,\n",
       "               'low': 142.55850649796298,\n",
       "               'med': 153.21715102586228})},\n",
       " 'vgood': {0: defaultdict(float,\n",
       "              {'high': 101.32695315584459,\n",
       "               'low': 107.14203121442817,\n",
       "               'med': 103.7861820612287,\n",
       "               'vhigh': 110.84580227927894}),\n",
       "  1: defaultdict(float,\n",
       "              {'high': 108.47046101571543,\n",
       "               'low': 108.91555978339372,\n",
       "               'med': 102.90556320454216,\n",
       "               'vhigh': 102.80938470712891}),\n",
       "  2: defaultdict(float,\n",
       "              {'2': 103.23490423460605,\n",
       "               '3': 107.95590864581371,\n",
       "               '4': 103.2268070496952,\n",
       "               '5more': 108.6833487806653}),\n",
       "  3: defaultdict(float,\n",
       "              {'2': 139.64216495640076,\n",
       "               '4': 141.36087470213235,\n",
       "               'more': 142.0979290522471}),\n",
       "  4: defaultdict(float,\n",
       "              {'big': 144.14721153849783,\n",
       "               'med': 139.1486183135147,\n",
       "               'small': 139.80513885876772}),\n",
       "  5: defaultdict(float,\n",
       "              {'high': 144.94000935001947,\n",
       "               'low': 135.0843417529914,\n",
       "               'med': 143.07661760776944})}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def train_unsupervised(df):\n",
    "    \"\"\"\n",
    "    Builds an unsupervised Naive Bayes model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get a list of the unique class labels\n",
    "    class_labels = df.iloc[:,-1].unique()\n",
    "    \n",
    "    # The list containing random class\n",
    "    # distributions for each instance.\n",
    "    random_class_distributions = []\n",
    "    \n",
    "    \n",
    "    # For each training instance, create\n",
    "    # a non-uniform class distribution for\n",
    "    # that instance.\n",
    "    for _ in df.values:\n",
    "        \n",
    "        random_class_distributions.append(\n",
    "            np.random.dirichlet(np.ones(len(class_labels)),size=1)[0])\n",
    "        \n",
    "    \n",
    "    # Make a new dataframe consisting of random class distributions\n",
    "    # for each instance.\n",
    "    new_df = pd.DataFrame(random_class_distributions, \n",
    "                          columns=class_labels)   \n",
    "        \n",
    "    \n",
    "    # Fuck the class labels mate\n",
    "    df = df.iloc[:,:-1]\n",
    "    \n",
    "    \n",
    "    # Dictionary contains the (random) frequencies\n",
    "    # of each class in the training set\n",
    "    class_freqs = defaultdict(int) \n",
    "    \n",
    "    \n",
    "    # Count the frequencies\n",
    "    for class_label in class_labels:\n",
    "        class_freqs[class_label] = new_df[class_label].sum()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialise the unsupervised Naive Bays model, which\n",
    "    # is just a dictionary of dictionaries of dictionaries\n",
    "    unsupervised_model = {c:{i:defaultdict(float) for i in range(df.shape[1])} for c in class_labels}\n",
    "    \n",
    "    \n",
    "    # Concatenate the dataframes\n",
    "    df2 = pd.concat([df, new_df], axis=1)\n",
    "    \n",
    "    \n",
    "    # For every instance in the training\n",
    "    # data, update the unsupervised model\n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        for attr in df.columns:\n",
    "            \n",
    "            for class_label in class_labels:\n",
    "                \n",
    "                unsupervised_model[class_label][attr][df2[attr][i]] += df2[class_label][i]\n",
    "                \n",
    "                \n",
    "                \n",
    "    return unsupervised_model\n",
    "\n",
    "\n",
    "\n",
    "# Test the function\n",
    "s = train_unsupervised(df)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: acc\n",
      "Class label: good\n",
      "Class label: unacc\n",
      "Class label: vgood\n",
      "Total instances: 1727\n"
     ]
    }
   ],
   "source": [
    "# Show that the unsupervised model is working, but there\n",
    "# could possibly be some underflow\n",
    "\n",
    "class_freqs = []\n",
    "\n",
    "for class_label in sorted(df.iloc[:,-1].unique()):\n",
    "    print(\"Class label: \" + class_label)\n",
    "    for attr in range(0,6):\n",
    "        total_class_instances = sum(s[class_label][attr].values())\n",
    "        \n",
    "        if int(total_class_instances) not in class_freqs:\n",
    "            class_freqs.append(int(total_class_instances))\n",
    "\n",
    "print(\"Total instances: {:4d}\".format(sum(class_freqs)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['unacc', 'acc', 'vgood', 'good'])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should predict the class distribution for a set of instances, based on a trained model\n",
    "def predict_unsupervised():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in an unsupervised manner\n",
    "def evaluate_unsupervised():\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. Since we’re starting off with random guesses, it might be surprising that the unsupervised NB works at all. Explain what characteristics of the data cause it to work pretty well (say, within 10% Accuracy of the supervised NB) most of the time; also, explain why it utterly fails sometimes.\n",
    "2. When evaluating supervised NB across the four different datasets, you will observe some variation in effectiveness (e.g. Accuracy). Explain what causes this variation. Describe and explain any particularly suprising results.\n",
    "3. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out (hint: check out numpy.shuffle()) or cross–validation evaluation strategy. How does your estimate of Accuracy change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "4. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Do you notice any variation in the predictions made by either the supervised or unsupervised NB classifiers? Explain why, or why not.\n",
    "5. The lecture suggests that deterministically labelling the instances in the initialisation phase of the unsupervised NB classifier “doesn’t work very well”. Confirm this for yourself, and then demonstrate why.\n",
    "6. Rather than evaluating the unsupervised NB classifier by assigning a class deterministically, instead calculate how far away the probabilistic estimate of the true class is from 1 (where we would be certain of the correct class), and take the average over the instances. Does this performance estimate change, as we alter the number of iterations in the method? Explain why.\n",
    "7. Explore what causes the unsupervised NB classifier to converge: what proportion of instances change their prediction from the random assignment, to the first iteration? From the first to the second? What is the latest iteration where you observe a prediction change? Make some conjecture(s) as to what is occurring here.\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question. Groups of 2 students should respond to question (1), and three other questions. Your responses should be about 100-200 words each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
